services:
  postgres_people:
    image: postgres:13
    container_name: postgres_people
    environment:
      POSTGRES_USER: admin
      POSTGRES_PASSWORD: admin
      POSTGRES_DB: people
    ports:
      - "5432:5432"
    volumes:
      - postgres_people_data:/var/lib/postgresql/data
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U admin -d people"]
      interval: 5s
      timeout: 5s
      retries: 5
    networks:
      - etl_net

  postgres_stage:
    image: postgres:13
    container_name: postgres_stage
    environment:
      POSTGRES_USER: admin
      POSTGRES_PASSWORD: admin
      POSTGRES_DB: stage_layer
    ports:
      - "5433:5432"
    volumes:
      - postgres_stage_data:/var/lib/postgresql/data
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U admin -d stage_layer"]
      interval: 5s
      timeout: 5s
      retries: 5
    networks:
      - etl_net

  mongodb:
    image: mongo:6
    container_name: mongodb
    environment:
      MONGO_INITDB_ROOT_USERNAME: admin
      MONGO_INITDB_ROOT_PASSWORD: admin
    ports:
      - "27017:27017"
    volumes:
      - mongodb_data:/data/db
    healthcheck:
      test: ["CMD", "mongosh", "--eval", "db.adminCommand('ping')"]
      interval: 5s
      timeout: 5s
      retries: 5
    networks:
      - etl_net

  zookeeper:
    image: confluentinc/cp-zookeeper:7.3.0
    container_name: zookeeper
    environment:
      ZOOKEEPER_CLIENT_PORT: 2181
      ZOOKEEPER_TICK_TIME: 2000
    ports:
      - "2181:2181"
    networks:
      - etl_net

  kafka:
    image: confluentinc/cp-kafka:7.3.0
    container_name: kafka
    depends_on:
      - zookeeper
    environment:
      KAFKA_BROKER_ID: 1
      KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka:9092,PLAINTEXT_HOST://localhost:29092
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: PLAINTEXT:PLAINTEXT,PLAINTEXT_HOST:PLAINTEXT
      KAFKA_INTER_BROKER_LISTENER_NAME: PLAINTEXT
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
      KAFKA_AUTO_CREATE_TOPICS_ENABLE: 'true'
    ports:
      - "9092:9092"
      - "29092:29092"
    healthcheck:
      test: ["CMD", "kafka-topics", "--bootstrap-server", "localhost:9092", "--list"]
      interval: 10s
      timeout: 5s
      retries: 5
    networks:
      - etl_net

  clickhouse:
    image: clickhouse/clickhouse-server:23.3
    container_name: clickhouse
    ports:
      - "8123:8123"
      - "9000:9000"
    volumes:
      - ./clickhouse-config/users.xml:/etc/clickhouse-server/users.xml
      - clickhouse_data:/var/lib/clickhouse
    healthcheck:
      test: wget --no-verbose --tries=1 --spider http://localhost:8123/ping || exit 1
      interval: 5s
      timeout: 3s
      retries: 10
    networks:
      - etl_net

  spark-master:
    image: bitnami/spark:3.4.0
    container_name: spark-master
    environment:
      - SPARK_MODE=master
    ports:
      - "8080:8080"
      - "7077:7077"
    networks:
      - etl_net

  spark-worker:
    image: bitnami/spark:3.4.0
    container_name: spark-worker
    environment:
      - SPARK_MODE=worker
      - SPARK_MASTER_URL=spark://spark-master:7077
      - SPARK_WORKER_MEMORY=2G
      - SPARK_WORKER_CORES=2
    depends_on:
      - spark-master
    networks:
      - etl_net
      
  airflow-webserver:
    build:
      context: .
      dockerfile: Dockerfile.airflow
    container_name: airflow-webserver
    depends_on:
      - airflow-scheduler
    environment:
      AIRFLOW__CORE__EXECUTOR: LocalExecutor
      AIRFLOW__DATABASE__SQL_ALCHEMY_CONN: postgresql+psycopg2://admin:admin@postgres_stage:5432/stage_layer
    volumes:
      - ./pipeline/processing/batch:/opt/airflow/dags
    ports:
      - "8081:8080"
    command: webserver
    networks:
      - etl_net

  airflow-scheduler:
    build:
      context: .
      dockerfile: Dockerfile.airflow
    container_name: airflow-scheduler
    depends_on:
      postgres_stage:
        condition: service_healthy
    environment:
      AIRFLOW__CORE__EXECUTOR: LocalExecutor
      AIRFLOW__DATABASE__SQL_ALCHEMY_CONN: postgresql+psycopg2://admin:admin@postgres_stage:5432/stage_layer
    volumes:
      - ./pipeline/processing/batch:/opt/airflow/dags
    command: scheduler
    networks:
      - etl_net

  grafana:
    image: grafana/grafana:9.5.2
    container_name: grafana
    depends_on:
      - clickhouse
    ports:
      - "3000:3000"
    volumes:
      - grafana_data:/var/lib/grafana
      - ./grafana/provisioning:/etc/grafana/provisioning
    environment:
      - GF_INSTALL_PLUGINS=vertamedia-clickhouse-datasource
    networks:
      - etl_net

  data-generator:
    container_name: data-generator
    build:
      context: .
      dockerfile: Dockerfile.data-generator
    depends_on:
      postgres_people:
        condition: service_healthy
      mongodb:
        condition: service_healthy
      kafka:
        condition: service_healthy
    volumes:
      - ./data:/app/data
    networks:
      - etl_net

  data-processing:
    container_name: data-processing
    build:
      context: .
      dockerfile: Dockerfile.data-processing
    depends_on:
      postgres_stage:
        condition: service_healthy
      kafka:
        condition: service_healthy
      clickhouse:
        condition: service_healthy
    volumes:
      - ./data:/app/data
      - ./pipeline/stage_layer:/app/pipeline/stage_layer
      - ./pipeline/processing/streaming:/app/pipeline/processing/streaming
      - ./pipeline/processing/clickhouse_views:/app/pipeline/processing/clickhouse_views
    networks:
      - etl_net

  app:
      build: .
      ports:
        - "8000:8000"
      networks:
        - etl_net

volumes:
  postgres_people_data:
  postgres_stage_data:
  mongodb_data:
  clickhouse_data:
  grafana_data:

networks:
  etl_net:
    driver: bridge